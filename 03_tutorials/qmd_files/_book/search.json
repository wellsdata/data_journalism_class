[
  {
    "objectID": "start-math.html",
    "href": "start-math.html",
    "title": "3  Newsroom math",
    "section": "",
    "text": "Jo Craven McGinty, then of The New York Times, used simple rates and ratios to discover that a 6-story brick New Jersey hospital was the most expensive in the nation. In 2012, Bayonne Medical Center “charged the highest amounts in the country for nearly one-quarter of the most common hospital treatments,” the Times story said.\nTo do this story, McGinty only needed to know the number of the procedures reported to the government and the total amount each hospital charged. Dividing those to find an average price, then ranking the most common procedures, led to this surprising result."
  },
  {
    "objectID": "start-math.html#why-numbers",
    "href": "start-math.html#why-numbers",
    "title": "3  Newsroom math",
    "section": "3.1 Why numbers?",
    "text": "3.1 Why numbers?\nUsing averages, percentages and percent change is the bread and butter of data journalism, leading to stories ranging from home price comparisons to school reports and crime trends. It may have been charming at one time for reporters to announce that they didn’t “do” math, but no longer. Instead, it is now an announcement that the reporter can only do some of the job. You will never be able to tackle complicated, in-depth stories without reviewing basic math.\nThe good news is that most of the math and statistics you need in a newsroom isn’t nearly as difficult as high school algebra. You learned it somewhere around the 4th grade. You then had a decade to forget it before deciding you didn’t like math. But mastering this most basic arithmetic again is a requirement in the modern age.\nIn working with typical newsroom math, you will need to learn how to:\n\nOvercome your fear of numbers\nIntegrate numbers into your reporting\nRoutinely compute averages, differences and rates\nSimplify and select the right numbers for your story\n\nWhile this chapter covers general tips, you can find specific instructions for typical newsroom math in this Appendix A, an except from Sarah Cohen’s outstanding book, Numbers in the Newsroom."
  },
  {
    "objectID": "start-math.html#overcoming-your-fear-of-math",
    "href": "start-math.html#overcoming-your-fear-of-math",
    "title": "3  Newsroom math",
    "section": "3.2 Overcoming your fear of math",
    "text": "3.2 Overcoming your fear of math\nWhen we learned to read, we got used to the idea that 26 letters in American English could be assembled into units that we understand without thinking – words, sentences, paragraphs and books. We never got the same comfort level with 10 digits, and neither did our audience.\nIn modern reporting, we’re dealing with huge numbers, in the millions and billions. Think of ways to put these figures into context for everyday people. For example, a million seconds goes by in about 11 days but you may not have been alive for a billion seconds – about 36 years.\nThe easiest way to get used to some numbers is to learn ways to cut them down to size by calculating rates, ratios or percentages. In your analysis, keep an eye out for the simplest accurate way to characterize the numbers you want to use. “Characterize” is the important word here – it’s not usually necessary to be overly precise so long as your story doesn’t hinge on a nuanced reading of small differences.\nHere’s one example of putting huge numbers in perspective. Pay attention to what you really can picture - it’s probably the $21 equivalent.\n\nThe Chicago hedge fund billionaire Kenneth C. Griffin, for example, earns about $68.5 million a month after taxes, according to court filings made by his wife in their divorce. He has given a total of $300,000 to groups backing Republican presidential candidates. That is a huge sum on its face, yet is the equivalent of only $21.17 for a typical American household, according to Congressional Budget Office data on after-tax income.  “Buying Power”, Nicholas Confessore, Sarah Cohen and Karen Yourish, The New York Times, October 2015\n\nOriginally the reporters had written it even more simply, but editors found the facts so unbelievable that they wanted give readers a chance to do the math themselves. That’s reasonable, but here’s an even simpler way to say it: “earned nearly $1 billion after taxes…He has given $300,000 to groups backing candidates, the equivalent of a dinner at Olive Garden for the typical American family , based on Congressional Budget Office income data.” (And yes, the reporter checked the price for an Olive Garden meal at the time for four people.)"
  },
  {
    "objectID": "start-math.html#put-math-in-its-place",
    "href": "start-math.html#put-math-in-its-place",
    "title": "3  Newsroom math",
    "section": "3.3 Put math in its place",
    "text": "3.3 Put math in its place\nFor journalists, numbers – or facts – make up the third leg of a stool supported by human stories or anecdotes , and insightful comment from experts. They serve us in three ways:\n\nAs summaries. Almost by definition, a number counts something, averages something, or otherwise summarizes something. Sometimes, it does a good job, as in the average height of Americans. Sometimes it does a terrible job, as in the average income of Americans. Try to find summaries that accurately characterize the real world.\nAs opinions. Sometimes it’s an opinion derived after years of impartial study. Sometimes it’s an opinion tinged with partisan or selective choices of facts. Use them accordingly.\nAs guesses. Sometimes it’s a good guess, sometimes it’s an off-the-cuff guess. Even when everything is presumably counted many times, it’s still a (very nearly accurate) guess. Yes, the “audits” of presidential election results in several states in 2021 found a handful of errors – not a meaningful number, but a few just the same.\n\nOnce you find the humanity in your numbers, by cutting them down to size and relegating them to their proper role, you’ll find yourself less fearful. You may even find that finding facts on your own is fun."
  },
  {
    "objectID": "start-math.html#going-further",
    "href": "start-math.html#going-further",
    "title": "3  Newsroom math",
    "section": "3.4 Going further",
    "text": "3.4 Going further\n\nTipsheets\n\nSteve Doig’s “Math Crib Sheet”\nAppendix A: Common newsroom math, adapted from drafts of the book Numbers in the Newsroom, by Sarah Cohen.\nA viral Twitter thread:\n\nWhat happens in your head when you do 27+48?--- Gene Belcher (@Wparks91) June 25, 2019"
  },
  {
    "objectID": "start-story.html",
    "href": "start-story.html",
    "title": "2  Learn a new way to read",
    "section": "",
    "text": "Getting started in data journalism often feels as if you’ve left the newsroom and entered the land of statistics, computer programming and data science. This chapter will help you start seeing data reporting in a new way, by learning how to study great works of the craft as a writer rather than a reader.\nJelani Cobb tweeted, “an engineer doesn’t look at a bridge the same way pedestrians or drivers do.” They see it as a “language of angles and load bearing structures.” We just see a bridge. While he was referring to long-form writing, reporting with data can also be learned by example – if you spend enough time with the examples.\nAlmost all good writers and reporters try to learn from exemplary work. I know more than one reporter who studies prize-winning journalism to hone their craft. This site will have plenty of examples, but you should stay on the lookout for others."
  },
  {
    "objectID": "start-story.html#read-like-a-reporter",
    "href": "start-story.html#read-like-a-reporter",
    "title": "2  Learn a new way to read",
    "section": "2.1 Read like a reporter",
    "text": "2.1 Read like a reporter\nTry to approach data or empirical reporting as a reporter first, and a consumer second. The goal is to triangulate how the story was discovered, reported and constructed. You’ll want to think about why this story, told this way, at this time, was considered newsworthy enough to publish when another approach on the same topic might not have been.\n\nWhat were the questions?\nIn data journalism, we often start with a tip, or a hypothesis. Sometimes it’s a simple question. Walt Bogdanich of The New York Times is renowned for seeing stories around every corner. Bogdanich has said that the prize-winning story “A Disability Epidemic Among a Railroad’s Retirees” came from a simple question he had when railway workers went on strike over pension benefits – how much were they worth? The story led to an FBI investigation and arrests, along with pension reform at the largest commuter rail in the country.\nThe hypothesis for some stories might be more directed. In 2021, the Howard Center for Investigative Journalism at ASU published “Little victims everywhere”, a set of stories on the lack of justice for survivors of child sexual assault on Native American reservations. That story came after previous reporters for the center analyzed data from the Justice Department showing that the FBI dropped most of the cases it investigated, and the Justice Department then only prosecuted about half of the matters referred to it by investigators. The hypothesis was that they were rarely pursued because federal prosecutors – usually focused on immigration, white collar crime and drugs – weren’t as prepared to pursue violent crime in Indian Country.\nWhen studying a data-driven investigation, try to imagine what the reporters were trying to prove or disprove, and what they used to do it. In journalism, we rely on a mixture of quantitative and qualitative methods. It’s not enough to prove the “numbers” or have the statistical evidence. That is just the beginning of the story. We are supposed to ground-truth them with the stories of actual people and places.\n\n\nGo beyond the numbers\nIt’s easy to focus on the numbers or statistics that make up the key findings, or the reason for the story. Some reporters make the mistake of thinking all of the numbers came from the same place – a rarity in most long-form investigations. Instead, the sources have been woven together and are a mix of original research and research done by others. Try to pay attention to any sourcing done in the piece. Sometimes, it will tell you that the analysis was original. Other times it’s more subtle.\nBut don’t just look at the statistics being reported in the story. In many (most?) investigations, some of the key people, places or time elements come directly from a database.\nSarah Cohen at Arizona State University analyzed the Paycheck Protection Program loan data for ProPublica and found a handful of sketchy-looking records from a single county in coastal New Jersey. It turned out to be a pretty good story.\nOften, the place that a reporter visits is determined by examples found in data. In this story on rural development funds, all of the examples came from an analysis of the database. Once the data gave us a good lead, the reporters examined press releases and other easy-to-get sources before calling and visiting the recipients or towns."
  },
  {
    "objectID": "start-story.html#reading-tips",
    "href": "start-story.html#reading-tips",
    "title": "2  Learn a new way to read",
    "section": "2.2 Reading tips",
    "text": "2.2 Reading tips\nYou’ll get better at reading investigations and data-driven work over time, but for now, remember to go beyond the obvious:\n\nWhere might the reporters have found their key examples, and what made them good characters or illustrations of the larger issue? Could they have come from the data?\nWhat do you think came first – a narrative single example that was broadened by data (naively, qualitative method), or a big idea that was illustrated with characters (quantitative method)?\nWhat records were used? Were they public records, leaks, or proprietary data?\nWhat methods did they use? Did they do their own testing, use statistical analysis, or geographic methods? You won’t always know, but look for a methodology section or a description alongside each story.\nHow might you localize or adapt these methods to find your own stories?\nPick out the key findings (usually in the nut graf or in a series of bullets after the opening chapter): are they controversial? How might they have been derived? What might have been the investigative hypothesis? Have they given critics their due and tried to falsify their own work?\nHow effective is the writing and presentation of the story? What makes it compelling journalism rather than a dry study? How might you have done it differently? Is a video story better told in text, or would a text story have made a good documentary? Are the visual elements well integrated? Does the writing draw you in and keep you reading? Think about structure, story length, entry points and graphics all working together.\nAre you convinced? Are there holes or questions that didn’t get addressed?"
  },
  {
    "objectID": "start-story.html#analyze-data-for-story-not-study",
    "href": "start-story.html#analyze-data-for-story-not-study",
    "title": "2  Learn a new way to read",
    "section": "2.3 Analyze data for story, not study",
    "text": "2.3 Analyze data for story, not study\nAs journalists we’ll often be using data, social science methods and even interviewing differently than true experts. We’re seeking stories, not studies. Recognizing news in data is one of the hardest skills for less experienced reporters new to data journalism. This list of potential newsworthy data points is adapted from Paul Bradshaw’s “Data Journalism Heist”.\n\n\n\n\nCompare the claims of powerful people and institutions against facts – the classic investigative approach.\nReport on unexpected highs and lows (of change, or of some other characteristic)\nLook for outliers – individual values that buck a trend seen in the rest\nVerify or bust some myths\nFind signs of distress, happiness or dishonesty or any other emotion.\nUncover new or under-reported long-term trends.\nFind data suggesting your area is the same or different than most others of its kind.\n\nBradshaw also did a recent study of data journalism pieces: “Here are the angles journalists use most often to tell the stories in data”, in Online Journalism Blog. I’m not sure I agree, only because he’s looking mainly at visualizations rather than stories, but they’re worth considering."
  },
  {
    "objectID": "xl-filter-sort.html#a-sorting-miracle",
    "href": "xl-filter-sort.html#a-sorting-miracle",
    "title": "7  Sorting and filtering to find stories",
    "section": "7.1 A sorting miracle",
    "text": "7.1 A sorting miracle\nAfter police in Ferguson, Mo., killed Michael Brown in 2014, advocates and journalists began examining the racial and ethnic gaps between police departments and the communities they served.\nThe New York Times found a 7-year-old survey conducted by the Justice Department that allowed it to compare the data for major cities in a standalone graphic that it published later that year.\nWhen newer data reflecting departments’ makeup in 2012 was released a year later, Matt Apuzzo and Sarah Cohen hoped it would show some differences. It didn’t. So we were left trying to find news in the data that was clearly of public interest.\nCohen matched up the demographics of police departments with their cities and then started sorting, filtering and Googling. Could there be news in the outliers on the list? Which departments most closely represented their communities? Which ones had unusually large gaps?\n\n\n\n\nChief William T. Riley III. Credit: Laura McDermott for The New York Times\n\n\n\nCohen quickly stumbled on telling anecdote to frame the story: Inkster, Mich. had one of the least representative departments in the country, and had recently hired a new police chief to help mend the department’s fraught relationship with its largely African-American community. Where had he come from? Selma, Ala., one of the most representative police departments in the nation. Interviews with the chief, William T. Riley III, suggested one reason for some cities’ disparities: there was no state or federal money to pay for training new police officers.\nThe story, “Police Chiefs, Looking to Diversity Forces, Face Structural Hurdles” helped explain the persistent gap between the makeup of police in some areas and the communities they served."
  },
  {
    "objectID": "xl-filter-sort.html#sorting-and-filtering-as-a-reporting-tool",
    "href": "xl-filter-sort.html#sorting-and-filtering-as-a-reporting-tool",
    "title": "7  Sorting and filtering to find stories",
    "section": "7.2 Sorting and filtering as a reporting tool",
    "text": "7.2 Sorting and filtering as a reporting tool\nSorting and filtering can:\n\nNarrow your focus to specific items that you want to examine in your story.\nShow you rows containing the highest and lowest values of any column. That can be news or it can be errors or other problems with the data.\nLet you answer quick “how many?” questions, with a count of the rows that match your criteria. (In the next lesson, you’ll see that pivot tables, or group-by queries, are much more powerful for this in most cases.)"
  },
  {
    "objectID": "xl-filter-sort.html#example-data",
    "href": "xl-filter-sort.html#example-data",
    "title": "7  Sorting and filtering to find stories",
    "section": "7.3 Example data",
    "text": "7.3 Example data\nData from the Washington Post police shootings database for use in this tutorial - Documentation from the Post’s github site :::\n\nThe data for this and several other chapters is the Washington Post’s public data collection of police shootings in the U.S. It includes the nation’s best guess about each fatal police shooting since 2015. There are a couple of caveats:\nIt excludes deadly police interactions other than shooting a firarem at the suspect. Any strangulation, car crashes, Tasers without guns or other methods are excluded.\nIt is based primarily on news reports and the results public records requests so it often contains the story as told by police. We know that many of those reports are sugar-coated at best, and lies at worst.\nThe Post says this is a list of fatal shootings, but doesn’t say what happens if more than one person is killed. The 2019 shooting of D’Angelo Brown & Megan Rivera in West Memphis is shown as two rows1 in the data even though it was one event. So each row might be considered a shooting “victim”, a “suspect” or a shooting “fatality” rather than a “shooting”.\n\nThe screenshots in this tutorial may not match exactly to what you get on the Washington Post data. This tutorial used data current to Aug. 3, 2022.\nIt’s a good example set for us because it’s been used as the basis of many stories, it has at least one of each data type that we plan to deal with in Google Sheets, and it is well documented on the Post’s github site."
  },
  {
    "objectID": "xl-filter-sort.html#get-the-data-into-google-sheets",
    "href": "xl-filter-sort.html#get-the-data-into-google-sheets",
    "title": "7  Sorting and filtering to find stories",
    "section": "7.4 Get the data into Google Sheets",
    "text": "7.4 Get the data into Google Sheets\n\nDownload the police shooting data from the Washington Post\nOpen Google Sheets. File | Import | Upload | Select the downloaded file “fatal-police-shootings-data.csv” . After it uploads, select the green “Import Data” button."
  },
  {
    "objectID": "xl-filter-sort.html#understanding-data-types",
    "href": "xl-filter-sort.html#understanding-data-types",
    "title": "7  Sorting and filtering to find stories",
    "section": "7.5 Understanding data types",
    "text": "7.5 Understanding data types\nWhen you open the spreadsheet, the first thing to notice is its granularity. Unlike Census or budget spreadsheets, this is a list capturing specific characteristics of each fatality Each column has the same type of data from top to bottom. Those types are:\n\nText. Text or “character” columns can come in long or short form. When they are standardized (the values can contain only one of a small list of values), they’re called “categorical”. If they’re more free-form, they’re might be called “free text”. The computer doesn’t know the difference, but you should. The Post data has examples of both. In spreadsheets, text is left-justified (they move toward the left of the cell and will line up vertically at the beginning)\nNumbers. These are pure numbers with no commas, dollar signs or other embellishments. In Google Sheets, as we’ll see in the computing section, these can be formatted to look like numbers we care about , but underneath they’re just numbers. Adding up a column of numbers that has a word in it or has missing values will just be ignored in Google Sheets. It will trip up most other languages. These are right-justified, so the last digit is always lined up vertically.\nLogical: This is a subset of text. It can take one of only two values – yes or no, true or false. There is no “maybe”.\nDate and times: These are actual dates on the calendar, which have magical properties. Underneath, they are a number. In Google Sheets, that number is the number of days since Jan. 1, 1900.2 They can also have time attached to them, which in Google Sheets is a fraction of a day. What this means is that the number 44,536.5 is really Dec. 6, 2021 at noon. In Google Sheets, you use a format to tell the spreadsheet how you want to see the date or time, just the way you look at dollar values with commas and symbols. (If you get a spreadsheet with a lot of dates of 1/1/1900, it means there is a 0 in that column, which is sometimes a fill-in for “I don’t know.”)\n\nHere’s a picture of a date that is shown in a variety of formats.\n\n\n\ndate formats\n\n\nAll of these are the same, underlying value – the number at the left. Notice that all of these are right-justified.\nThis means that when you see “Friday, December 10”, the computer sees 44540.87431. When you put the dates in order, they won’t be alphabetized with all of the Fridays shown together. Instead, they’ll be arranged by the actual date and time.\nIt also means that you can compute 911 response times even when it crosses midnight, or or compute the someone’s age today given a date of birth. Keeping actual calendar dates in your data will give it much more power than just having the words. (Google Sheets uses the 1st of the month as a stand-in for an actual date when all you know is the month and year.)\n\n7.5.1 Sorting rows\nSorting means rearranging the rows of a data table into a different order. Some reporters take a conceptual shortcut and call this “sorting columns”. That thinking will only get you into trouble – it lets you forget that you want to keep the rows in tact while changing the order in which you see them. In fact, in other languages it’s called “order by” or “arrange” by one or more columns – a much clearer way to think of it.\nIn Google Sheets, look for the sort options under the Data tab at the top of your screen. In this case, sorting from oldest to newest gives you a list of the fatalities in chronological order, including the time of day.\nTo sort your data:\n\nMake a copy of your data. Left click on the “fatal-police-shootings-data” tab, select Duplicate\nSelect your data by clicking the box above Row 1 and to the left of Column A\nSelect Data | Sort Range | Advanced Range Sorting Options\nClick “Data has header row” and then select date from the Sort by dialog box. Select Z –&gt; A\nSelect Sort\n\n\n\n\nAdding fields to the sort\nAdding more columns to the sort box tells Google Sheets what to do when the first one is the same or tied. For example, sorting first by state then by date gives you a list that shows all of the events by state in sequence:\n\n\n\n\n7.5.2 Filtering\nFiltering means picking out only some of the rows you want to see based on a criteria you select in a column. Think of it as casting a fishing net – the more filters you add, the fewer fish will be caught.\nTo activate filters in Google Sheets, from the Menu:\n\nData | Filter Views | Create a New Filter View\nYou’ll see little triangles next to the column headings.\n\nClick the “armed” heading. You will see options for various weapons. All are selected by default with a check mark. To select just “ax”, click on clear and then select “ax.” The sheet how is filtered to just weapons using an ax. To remove the filter, repeat the steps and “select all” and the entire sheet is displayed again.\nEach filter you select adds more conditions, narrowing your net.\nTo find fatalities that involved a firearm with a Taser, use the drop-down menu under manner_of_death select “shot and Tasered”.\n\n\n\n\n\nThis method works for small-ish and simple-ish columns. If your column has more than 10,000 different entries, such as names or addresses, only the first 10,000 will be considered. We only caught these for stories when someone did a fact-check using a different method of filtering. If your column has a lot of distinct entries, use option that says “Choose One”, and then use the “Contains” option. Better yet, don’t use filtering for counting things at all.\nAdd more filters to narrow down your list of cases even more. For example, the New York Times ran a series of stories in 2021 about unarmed people shot by police. One story was about those who were fleeing by car. Here’s one way to get a preliminary list of those cases:\n\nRemove any filter you already have on.\nTurn on the filters again if you turned them off.\nChoose “unarmed” under armed and “car” under flee.\n\n(Of course, the Times didn’t stop there in trying to find more cases and teasing out more of them from this and other data. But this is a start. )\n\n\n\n\n\n\nDifferent kinds of filters\nThere are several filter options. You can filter by various conditions. For numerical data, you can set a minimum or maximum value or a range of values. This is useful for dates to specify a certain time period. For text, you can filter if a word contains a few letters, useful to capture spelling variations."
  },
  {
    "objectID": "xl-filter-sort.html#footnotes",
    "href": "xl-filter-sort.html#footnotes",
    "title": "7  Sorting and filtering to find stories",
    "section": "",
    "text": "Finding these is something that’s pretty hard in a spreadsheet but will be really easy in R.↩︎\nEach language deals with dates and times a little differently. We’ll see how R does it later on. But just know that dates can be tricky because of these differences and time is even more tricky↩︎"
  },
  {
    "objectID": "xl-pivot.html#tutorial",
    "href": "xl-pivot.html#tutorial",
    "title": "9  Grouping with pivot tables",
    "section": "9.1 Tutorial",
    "text": "9.1 Tutorial\n\nWe will continue to use data from the Washington Post police shootings database for this tutorial.\n\nFirst, let’s modify this spreadsheet to include the descriptions of race and ethnicities: A for Asian, B for Black, etc.\n\nSelect Column I, city, and insert a new column to the left. Name it race_ethicity\nCreate a filter. Select race, filter for A\nType Asian in Column I. Copy Asian down the entire column so every A in column H corresponds with Asian in Column I\nRepeat: B = Black. H = Hispanic. W = White, non-Hispanic, N= Native American, O=Other, blanks=Unknown.\n\nFollow this video to see the process.\n\n\n\nSetting up the pivot table\nFrom the main menu on Google Sheets, choose Insert, then Pivot table, then New sheet.\n\n\n\ninsert menu\n\n\nNext, you will see the Pivot Table editor. Here’s what it looks like:\n\n\n\npivot menu\n\n\n\n\nCounting , or “how many”?\nFor Rows, select Add and then race_ethnicity. For values, select Add and then state. You will now see all of the race and ethnicity totaled.\nWe’re totalling on state because it’s good to have something that’s always filled out into the Values area (state is a safe one in this data).\n\n\n\nPercents of total\nIt’s hard to compare raw numbers unless they’re really small. Instead, we’d like to know what percent of fatalities by ethnicity. To get a “Percent of Column total”, do the following:\n\nAdd a second values, select state\nUnder Show as, select “% of grand total”\n\n\n\n\nMore variables\nSuppose you’d like to see the number of fatalities by year, with the years across the top and the ethnicity down the sides. Add a year variable to columns\n\nRemove the percent of total column\nSelect Columns, then year\n\n\n\n\nEven more variables\nSay you wanted to see each city’s total shootings by year. Which one had the most last year, and which one had the most overall?\nThis is actually really hard in a pivot table, because there are cities with the same names in different states. It means you’d need to have a pivot table with TWO columns down the side, and one across the top. Here’s an attempt at solving the problems:\n\nFirst, Rows, add state\nRows, add city\nValues, add state, CountA is the default\nColumns, add year\n\n\n\n\nMore Variables!\n\n\nThe problems is we can’t sort by the combination of city and state. But it does help answer the question on some level."
  },
  {
    "objectID": "xl-pivot.html#faq",
    "href": "xl-pivot.html#faq",
    "title": "9  Grouping with pivot tables",
    "section": "9.2 FAQ",
    "text": "9.2 FAQ\n\nI have too many columns\nIf you want two sets of statistics – say, number of fatalities and percent of fatalities – across the top, it can get very wide and confusing very quickly. One alternative is to change it into more of a vertical rectangle by dragging the “Values” element from the columns to the rows on the right. (This only shows up when you have two calculations being made.)\n\n\nI want to sort by percents, not numbers\nYou can’t.\n\n\nThings aren’t adding up\nYou have to be super careful about which column you use to Count things – it has to always be filled out (there can’t be any blanks). Go through the filters and find one that doesnt have (Blanks) at the bottom to be sure.\n\n\nIts a crazy number!\nYou might have dragged a numeric column into the “Values” area. Check to see if it says “Count” or “Sum”. Change it to “Count” if it has something else on it, unless you wanted to add up that column.\n\n\nThis is so frustrating - I can’t get what I want\nRight? It’s time to go to a programming language!"
  },
  {
    "objectID": "r-start.html#install-r-and-rstudio",
    "href": "r-start.html#install-r-and-rstudio",
    "title": "11  Getting started with R and RStudio",
    "section": "11.1 Install R and RStudio",
    "text": "11.1 Install R and RStudio\n\nR is the programming language itself, and has to be installed first\nRStudio is a software program that makes it easier to interact with the programming language. Install it second.\nPackages are sets of programs written by volunteers and data scientists that perform specialized jobs more easily that working with the “base” R language. A package must be installed once on your computer, then invoked to use them in a program.\n\n\nFollow this interactive tutorial on installing R, RStudio and the tidyverse on your computer:\nhttps://learnr-examples.shinyapps.io/ex-setup-r/#section-welcome .\n\nThere are two differences between the video and today:\n\nThe tidyverse will take much longer to finish installation. It has a lot to do and often looks like it’s stalled.\nThere are two versions of R for Mac users: The traditional one and the one for the new M1 or M2 chip on the latest machines. Choose the one that matches your machine by checking the apple in the upper left and looking at “About this Mac”. It will say “Apple M1” or “Apple M2” as the processor if you have it."
  },
  {
    "objectID": "r-start.html#unlocking-packages-and-the-tidyverse",
    "href": "r-start.html#unlocking-packages-and-the-tidyverse",
    "title": "11  Getting started with R and RStudio",
    "section": "11.2 Unlocking packages and the tidyverse",
    "text": "11.2 Unlocking packages and the tidyverse\nThe real power of R comes with packages. Packages are bundles of programs that others have found useful to extend the base R language. R is almost useless without them. There are more than 10,000 packages available for R, each doing a special job.\nIf you followed along with the tutorial, the last thing you did was install a “package” called the tidyverse. Almost everything we do from now on depends on that step.\nThe tidyverse packages up a whole set of other packages that are designed to work together smoothly with similar grammar and syntax. It’s particularly useful for the kind of work reporters do – importing, cleaning and analyzing data that we get from others and can’t control how it’s structured.\nWe’ll be working almost exclusively within the tidyverse in this course. I strongly suggest that when you Google for help, put the word “tidyverse” somewhere in your query. Otherwise, you may get answers that look inscrutable and unfamiliar.\nThe tidyverse is the brainchild of Hadley Wickham, a statistician from New Zealand, who famously identified tidy data principles. He’s currently the chief data scientist for RStudio in Houston."
  },
  {
    "objectID": "r-start.html#set-up-rstudio-for-data-reporting",
    "href": "r-start.html#set-up-rstudio-for-data-reporting",
    "title": "11  Getting started with R and RStudio",
    "section": "11.3 Set up RStudio for data reporting",
    "text": "11.3 Set up RStudio for data reporting\nStaying organized is one of the challenges of data reporting – you’re constantly re-downloading and re-jiggering your analysis and it’s easy to get your material separated. This setup helps ensure that you always know where to find your work and can move it to another comptuer seamlessly.\nBefore you start, decide on a folder you’ll use to store all of your R work. Within my Documents folder, I created a sub-folder called data-class. It will make this guide a little easier if you do the same thing, especially if you’re not very familiar with using directories and folders.\n\n\n\nStart up RStudio once you’ve made your folder. Make sure you start up RStudio (not the R language) by searching for it in Spotlight or in the Search bar in Windows. Here’s what they look like:\n\nGet to the Preferences (under the RStudio menu item on a Mac) and make sure it looks like this in the General tab:\n\n\n\nsee below\n\n\n\n(I’ve turned OFF all of the options to restore anything when you start up RStudio and set up a default working directory by browsing to the one I just created.)\nUnder the R Markdown options, make sure that the box called “Execute setup chunk automatically” is checked."
  },
  {
    "objectID": "r-start.html#the-screen",
    "href": "r-start.html#the-screen",
    "title": "11  Getting started with R and RStudio",
    "section": "11.4 The screen",
    "text": "11.4 The screen\nThis is what your screen probably looks like:\n\n\n\nconsole\n\n\n\nThe Console\nThe Console is where you can type commands and interact directly with the programming language. Think of it as a very powerful calculator at first. One reason to use it is to install packages.\nIf you followed the installation demo, you’ve already used the console to install one package. (Go back and do that part now if you skipped it.) Install a few more that will be useful in this course.\n\nCopy these commands one a a time, and paste them into the Console, then hit Return/Enter to execute the command.\n   install.packages(\"janitor\")\n   install.packages(\"rmarkdown\")\n   install.packages(\"skimr\")\n   install.packages(\"swirl\")\n\nThese package names should all be in quotes. We’ll be installing other packages later in this guide, but for now that is everything you need.\n\n\nFiles tab\nWe won’t be using many of the tabs in the lower right, but the Files tab can help you if you’re having trouble navigating your work. Under the More button, you can choose “Go to working directory”, since that’s where R thinks you’ve parked all of your work. This can be confusing in R, which is why we’ll be working in “projects” that bundle up all of your work in one place.\n\n\nEnvironment\nThe upper right screen is the Environment, which is where your active variables live. A variable is a named thing. It might be a word, a list of words or numbers, or a data frame (spreadsheet). Anything that you want to use has to be listed in that environment before you can reference it. This will make more sense later.\n\n\nTyping into the console\nWhen you type this: 5+5 after the &gt; prompt, you’ll get this back after you press Return/Enter: [1] 10\nWhen you type this: \"Merrill\" (with quotes) after the &gt; prompt, you’ll get this back: [1] \"Merrill\"\nTo create a new variable, you’ll use the assignment operator &lt;- (two characters : A less than sign and a hyphen). Here is how I would create the variable called my_name (lower case, no spaces). Notice how it appears in the Environment after being created. Then I can print it by typing the name of the variable instead of the letters of my name in quotes:\n\n\n\n\n\nThe console remembers your commands, but you have to type them one at a time and it will forget them when you leave for the day. That’s why we’re going to work in programs called R Markdown documents most of the time."
  },
  {
    "objectID": "r-start.html#working-directory",
    "href": "r-start.html#working-directory",
    "title": "11  Getting started with R and RStudio",
    "section": "11.5 Working directory",
    "text": "11.5 Working directory\nHere’s how to set your working directory so you can keep your files organized. First, you should have created a folder within the Documents folder called data_class. Run the following command to see if R Studio is pointing to that folder\n\ngetwd()\n\n[1] \"/Users/robwells/Code/data_journalism_class/03_tutorials/qmd_files\"\n\n\nIf it is not, you can navigate R Studio to that folder using the Files tab in the lower right corner window. Once you find your data_class folder, then select the Set Working Directory option under the More menu.\nYou can also set the path programmatically using setwd() which means set working directory. Just find the path directory using Finder – directions are here – and copy that link to this command.\n\nsetwd(\"/Users/YOURNAME/Documents/data_class\")"
  },
  {
    "objectID": "r-start.html#interactive-r-tutorial",
    "href": "r-start.html#interactive-r-tutorial",
    "title": "11  Getting started with R and RStudio",
    "section": "11.6 Interactive R tutorial",
    "text": "11.6 Interactive R tutorial\nOne of the packages you installed earler was called swirl. Invoke it now by typing library(swirl) into the Console. You can follow the instructions from there. Don’t bother going beyond the first chapter – it’s more geared at other kinds of jobs than ours.\n\n\n\nRelax by Silwia Bartyzel via Unsplash"
  },
  {
    "objectID": "r-start.html#relax",
    "href": "r-start.html#relax",
    "title": "11  Getting started with R and RStudio",
    "section": "11.7 Relax!",
    "text": "11.7 Relax!\nYou’re all set up and we’re ready to start programming. Congratulate yourself - everything is new, nothing is intuitive and the screen is intimidating. You’ve come a long way."
  },
  {
    "objectID": "r-start.html#other-resources",
    "href": "r-start.html#other-resources",
    "title": "11  Getting started with R and RStudio",
    "section": "11.8 Other resources",
    "text": "11.8 Other resources\nSharon Machlis’ Practical R for Mass Communications and Journalism has an intro to R and RStudio in chapters 2.3 through 2.6\nBen Stenhaug created a fast-paced video introducing the RStudio interface. Don’t worry too much about what some of it means just yet – just see if you can get used to the different parts of the screen."
  },
  {
    "objectID": "xl-sheets_cleaning.html",
    "href": "xl-sheets_cleaning.html",
    "title": "10  Cleaning data with Google Sheets",
    "section": "",
    "text": "This chapter will demonstrate some of the bedrock data cleaning skills using Google Sheets, techniques that can be used in Excel and other spreadsheets. We will normalize and clean data by deleting rows, stripping whitespace, making characters lowercase or uppercase. In addition, you will learn to split text to columns, a very handy tool for splitting up dates.\nWe will use a version of the Washington Post police shooting data to conduct these exercises.\nMake a copy of your data before cleaning!\n\n10.0.1 Text to columns\nWe want to split up the date field into day, month and year. Currently, the format is 2015-01-02. Luckily, the fields all share a common separator, a hyphen, and we can ask Google Sheets to split all according to the hyphen. Other common separators are commas and spaces.\nFirst steps when modifying data: make a backup copy! - Left click on the tab “Police Shootings to Clean” - Select duplicate - Rename “Copy of Police Shootings to Clean” to “Original Police Shootings to Clean.” Do not touch this version.\nTime to split text to columns. I am extra paranoid (for good reason) and so I always duplicate a date field before modifying it. Duplicate the date column (click on Column C, left click, copy, then Insert column to left, select new blank Column C and paste), save the copy as date-original.\n\nSelect date column\nSelect Data | Split text to columns\nSee a dialog box: Separator. Select Custom and type in a dash - and enter. You now have the date field chopped up to year, month and day. Rename column E for month and column f for day.\n\n\n\n\n\n\n\n\n10.0.2 Normalizing\nScroll down the race_ethnicity column and you will see a number of different categories for the same thing: white, White, non Hispanic and Black, African Am. To see all the variations of categorical variables, create a filter and check the different variables\nThis presents a big problem when you are trying to group and summarize based on these variable names. See this chart\nWe see white totals 44 and White, non Hispanic total 3,136. We want those to be together – the total is 3,180 – because they are the same thing. Also note that African Am totals 29 and Black totals 1,645, and we would want to combine those as well.\nLet’s fix it!\nBefore changing any data, let’s work with a copy of the column. - Select race_ethnicity (Column k), left click, copy - Left click on Column K, insert column to right, paste - Rename as race_ethnicity2\nRenaming variables. We will rename all “white” as “White, non Hispanic” - Filter race_ethnicity (Column K) to white - in race_ethnicity2, write “White, non Hispanic” in the first column and copy down the list\nSee how this process works\n\n\n\n\n\n\n\n10.0.3 Lowercase or Uppercase character conversion\nCreate a filter and notice two variations on Native American: NativeAm and nativeam. You can resolve these differences easily by converting all to Upper or Lower case text using the =UPPER or =LOWER functions.\n\nTo convert NativeAm to lower case, filter on race_ethnicity (Column K) for NativeAm.\nIn race_ethnicity2 (Column L), insert a blank column, and type the function =LOWER(K67) and hit enter.\n\nThe result should be nativeam as the first entry in race_ethnicity2.\nSee this example\n\n\n10.0.4 White space\nOne obnoxious feature of spreadsheet data is the invisible “white space” or hidden character or carriage returns that can impede your ability to group and summarize variables. Look at the age column. See how some numbers are flush left while most are flush right. The flush left data has hidden white space. You can fix this by clicking on individual cells and deleting the space around the number or you can do it with a function.\n\nSelect age (Column H), left click on Column H, insert column to right, rename as age2\nIn cell I2, type =TRIM(H2) and enter. Copy the formula down.\n\nNote how all of the values have been normalized.\nThese are some of the basic go-to tools for data cleaning in Google Sheets, which can be adapted to Excel, R and other programming languages."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Journalism with R and the Tidyverse",
    "section": "",
    "text": "1 Introduction\nWelcome to data journalism. The main goal of this course is to expand your ability to report and tell stories using data. You will use these tools to discover trends in data. You will learn how to create and publish graphics and maps. It’s hard work but it is a lot of fun and very rewarding.\nWe have some basic goals for you to reach in this class. By the end of the semester, we want you to have basic proficiency and independence with data analysis. We want you to be able to write about data clearly, using the Associated Press style as a benchmark. We want you to be able to find and download a dataset, clean it up, visualize it.\nThe skills you will learn in the coming weeks are in high demand in journalism and beyond. Examine this BuzzFeed job description from 2017:\n“We’re looking for someone with a passion for news and a commitment to using data to find amazing, important stories — both quick hits and deeper analyses that drive conversations,” the posting seeking a data journalist says. It goes on to list five things BuzzFeed is looking for: Excellent collaborator, clear writer, deep statistical understanding, knowledge of obtaining and restructuring data.\n“You should have a strong command of at least one toolset that (a) allows for filtering, joining, pivoting, and aggregating tabular data, and (b) enables reproducible workflows.”\nYou will learn these skills in this book. You’ll get a taste of modern data journalism through Google Sheets and programming in R, a statistics language. You’ll be challenged to think programmatically while thinking about a story you can tell to readers in a way that they’ll want to read. Combining them together has the power to change policy and expose injustice."
  },
  {
    "objectID": "index.html#installations",
    "href": "index.html#installations",
    "title": "Data Journalism with R and the Tidyverse",
    "section": "1.1 Installations",
    "text": "1.1 Installations\nThis book begins with a basic review of Google Sheets and then shifts to the R statistical language. To follow along, you’ll do the following:\n\nInstall the R language on your computer. Go to the this website, click download R based on your operating system. If that link somehow doesn’t work, check R Project website and find a different location.\nInstall R Studio Desktop. The free version is great.\n\nGoing forward, you’ll see passages like this:\n\ninstall.packages(\"tidyverse\")\n\nThat is code that you’ll need to run common software packages in your R Studio."
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "Data Journalism with R and the Tidyverse",
    "section": "1.2 About this book",
    "text": "1.2 About this book\nThis book is the collection of class materials compiled by various data journalism professors around the country: Matt Waite at the University of Nebraska-Lincoln’s College of Journalism and Mass Communications and Sarah Cohen of Arizona State University. This version was rewritten by Rob Wells, building on work by Sean Mussenden and Derek Willis, at the University of Maryland Philip Merrill College of Journalism.\nThere’s some things you should know about it:\n\nIt is free for students.\nThe topics will remain the same but the text is going to be constantly tinkered with.\nWhat is the work of the authors is copyright Rob Wells 2024, Sean Mussenden and Derek Willis 2022, Matt Waite 2020 and Sarah Cohen 2022.\nThe text is Attribution-NonCommercial-ShareAlike 4.0 International Creative Commons licensed. That means you can share it and change it, but only if you share your changes with the same license and it cannot be used for commercial purposes. I’m not making money on this so you can’t either.\nAs such, the whole book – authored in Quarto – in its original form is open sourced on Github. Pull requests welcomed!"
  },
  {
    "objectID": "index.html#what-well-cover",
    "href": "index.html#what-well-cover",
    "title": "Data Journalism with R and the Tidyverse",
    "section": "1.3 What we’ll cover",
    "text": "1.3 What we’ll cover\n\nSpreadsheets\nR Basics\nReplication, Data Diary\nData basics and structures\nAggregates\nMutating\nWorking with dates\nFilters\nData cleaning techniques, Janitor\nPulling Data from PDFs\nJoins\nBasic data scraping\nGetting data from APIs: Census\nVisualizing for reporting: Basics\nVisualizing for reporting: Publishing\nGeographic data basics\nGeographic queries\nGeographic visualization\nText analysis basics\nWriting with and about data\nData journalism ethics"
  },
  {
    "objectID": "census_data.html",
    "href": "census_data.html",
    "title": "4  Census Data",
    "section": "",
    "text": "We will be using data from the U.S. Census for many of these exercises. Here’s a quick rundown of the origins and inner-workings of this important dataset.\nEach decade, the Census Bureau counts every person living in the United States and the five U.S. territories. This is known as the Decennial Census and it is used to apportion seats in the U.S. House of Representatives, among other things.\nIn addition, the Census Bureau conducts ongoing survey of communities, known as the American Community Survey or ACS that provides more timely information about social, economic, housing, and demographic data every year. You can find information on housing, small business ownership, population profiles and much more. The ACS uses an annual sample size of about 3.5 million addresses and is collecting information daily.\nCongressional lawmakers look at the ACS data to determine distribution of federal spending, among other things. Read more about census data here\nHere’s something important to know about ACS results: Data are pooled across a calendar year. So the ACS numbers reflect data collected over a period of time. By contrast, the Decennial Census is a single point-in-time count of the population.\nWe will be using ACS data to examine trends in wealth and social issues in Baltimore neighborhoods because this survey provides detail not available yet in the Decennial Census.\nYou can access Census Data through multiple ways. The U.S. Census Bureau offers data.census.gov. Using this site requires some training and patience. Here is a good place to start, a presentation the Census Bureau staff made to the Investigative Reporters and Editors conference in 2019.\nAnother useful resource is censusreporter.org, a site not affiliated with the Census Bureau that’s designed to make it easier to navigate and retrieve the ACS data.\nWhen we use R, we will use a software library called tidycensus that makes it very easy to retrieve Census data from the Census API, or application programming interface, basically a raw data feed optimized for R, python and similar programs. Stay tuned on that later this semester.\nData journalist Paul Overberg, now with The Wall Street Journal, compiled this useful guide about terminology when dealing with Census data."
  },
  {
    "objectID": "xl-intro.html",
    "href": "xl-intro.html",
    "title": "5  Spreadsheets",
    "section": "",
    "text": "Introduction\nSpreadsheets are the gateway drug of data journalism.\nThey are fundamental for organizing data and doing quick calculations. The concepts of sorting, filtering and calculations with spreadsheets are adapted to advanced software. Every data journalist has a solid proficiency in spreadsheets. After readings this material and doing the exercises, you will be on your way too.\nSpreadsheets are great because it’s relatively easy to see what you’re doing and you can easily share your work with your colleagues. In fact, pieces of the Pulitzer-Prize winning COVID-19 coverage from The New York Times was compiled using an elaborate and highly tuned set of Google spreadsheets with dozens of contributors.\nThis guide uses Google Sheets, which allows students to do the exercises regardless of their computer operating system, Mac, Windows or Linux. The exercises can be easily adapted to Microsoft Excel, which can handle larger datasets and has more options for pivot tables and other more advanced functions. However, Google Sheets have their own advanced functions for scraping websites or importing non-tabular file formats like JSON.\nMost of the screen shots and instructions are created with a MacOS Monterey. Some come from earlier Mac versions, but are largely the same now. Windows users should replace any instructions for using the CMD- key with the CTL- key. There is a table that compares keystrokes for Apple desktops, laptops and Windows machines for Excel at the bottom of Spreadsheet Refresher"
  },
  {
    "objectID": "xl-intro.html#tutorials",
    "href": "xl-intro.html#tutorials",
    "title": "5  Spreadsheets",
    "section": "Tutorials",
    "text": "Tutorials\nSpreadsheets are used in almost every workplace in America. This section covers most of what you need in the newsroom.\n\nSpreadsheet Refresher : Start over with good habits\nSorting and filtering to find stories : The first step of interviewing data\nGrouping with pivot tables: Aggregating, and the super power of spreadsheets\nSpreadsheet Formulas: Percents, sums, and other basic computations used in newsrooms."
  },
  {
    "objectID": "xl-refresher.html#re-learning-excel-from-the-ground-up",
    "href": "xl-refresher.html#re-learning-excel-from-the-ground-up",
    "title": "6  Spreadsheet Refresher",
    "section": "6.1 Re-learning Excel from the ground up",
    "text": "6.1 Re-learning Excel from the ground up\n\nThe spreadsheet grid\n\n\n\nWhen you start up a spreadsheet, you’ll see letters across the top and numbers down the side. If you ever played Battleship, you’ll recognize the idea – every little square, or cell, is referenced by the intersection of its column letter and row number:\nB2 is the cell that is currently active. You can tell because it’s outlined in the sheet and it’s shown on the upper left corner.\n\n\nMouse shapes\n\n\n\n\n\n\n\nThe Copy Tool, or the thin black cross. When you see this, you’ll copy anything that’s selected. This can be good or bad.\n\n\n\nThe Evil Hand. If you use this symbol, you will MOVE the selection to a new location. This is very rarely a good idea or something you intend.\n\n\n\n\n\n\nSelecting cells and ranges\nSpreadsheets act only on the cells or regions you have selected. If you begin typing, you’ll start entering information into the currently selected cell.\nTo select: Hold the cursor over the cell and click ONCE – not twice. Check the formula bar to make sure you’ve selected what you think you’ve got. You can also look at the bottom right of your spreadsheet for more information.\nYou’ll often work with ranges of cells in formulas. These are defined by the corners of the area you want to work on – often a column of information. In the example below, the range is A1:C6, with the “:” referring to the word “through”.\nTo select a group of cells and act on them all at once: Hover the cursor over one corner, click ONCE and drag to the diagonal corner. Make sure the Evil Hand is nowhere to be seen. The entire area will be shaded in except for the currently selected cell. Look at the upper right corner to see how many rows and columns you selected.\n\n\n\n\n\n\n\n\nTo select a column or row : Hover the cursor over the letter at the top of the column. For a row, hover it over the row number in the margin\n\n\nReading the screen\n\nThe areas of the spreadsheet have different visual clues, and learning to read them will make your life much easier.\nThis image shows some key areas on the screen when you’re just viewing the sheet:\n\n\n\nRead the Screen\n\n\nThis is how it changes when you’re editing\n\n\n\nEditing\n\n\n\nEntering data\nSelect the cell and start typing. The information you type won’t be locked into the cell until you hit the Return / Enter key, or move your selection to another cell. Hit “Escape” to cancel the entry.\nYou can’t do a lot of things while you’re editing, so if you have a lot of greyed out menu items, look at your formula bar to see if you are still editing a cell.\nIf you’re having trouble getting to a menu item or seeing the result of your work, try hitting “Escape” and try again. You may not have actually entered the information into the sheet.\n\n\nLocking in headings\nAs your spreadsheet grows vertically with more rows, you’ll want to be able to see the top all the time. When it grows horizontally with more columns, you’ll probably want to see columns in the left, such as names. This is called “Freezing Panes” – you freeze part of the page so it stays in place when you move around.\nSelect View in the menu, then Freeze, then the number of rows to freeze. Select 1 row. As you now scroll down the sheet, your headings will remain but you can see the data as you move deeper into the sheet.\n\n\n\nfreeze panes\n\n\n\n\nFormatting tricks\n\nUse the buttons or the format dialog box to make numbers easier to read.\nIf a column is filled with a lot of text, select Format, then Wrapping from the menu to wrap text. This means that when you double-click to widen a column, it will get taller, not wider. This is good when you need to save valuable real estate on the screen."
  },
  {
    "objectID": "xl-refresher.html#getting-started-with-a-dataset",
    "href": "xl-refresher.html#getting-started-with-a-dataset",
    "title": "6  Spreadsheet Refresher",
    "section": "6.2 Getting started with a dataset",
    "text": "6.2 Getting started with a dataset\nSLOW DOWN! Don’t do anything until you understand what you have in front of you and can predict what your next mouse click will do to it.\nMost data we encounter was created by someone else for some purpose other than ours. This means that you can’t assume anything. It may not be complete. It may be inaccurate. It may mean something completely different than it appears at first blush.\n\nFirst steps\n\nDocument where you got the spreadsheet and how you can get back to the original. Create a new tab (click the + sign in the lower left), name it Data Dictionary, copy the URL of your source data and any other notes about it. Make this your regular practice. It will save time and stress on deadline.\nRead anything you can about what it contains. Look for documentation that comes with the data.\nSave the original into a safe place with its original name and metadata. Work on a copy.\nIf the spreadsheet shows #### instead of words or numbers, widen your columns. If it shows 7E-14 or something like that, format them as numbers, not “General”.\nCheck your corners – look at the top left and bottom right. Is the data all in one area? Are there footnotes or other non-data sections mixed in? We’re going to want to fix that later.\n\n\n\nInterview your data\n\nHeadings\nThe most fraught part of data reporting is understanding what each column actually means. These often have cryptic, bureaucratic names. You may need to go back to the source of the data to be sure you actually understand them.\nIf your data doesn’t have any headings, that’s going to be your first priority. In effect, you’ll need to build what we call a data dictionary or record layout if one hasn’t been provided. Many reporters create these as a page in a dataset.\n\n\nUnit of analysis\nA unit of analysis refers to the items that are listed in the rows of your dataset. Ideally, every row should be at the same unit of analysis – a person, an inspection, or a city, for example. Summaries should be separated by a blank row, or moved to a different sheet. Think of this as the noun you’d use to describe every row.\n\n\nRow numbers\nThe data was probably given to you in some sort of natural sort order. Different computer systems sort differently – some are case-sensitive, others are not. It may depend on when and where the data as created! The order of the data may even depend on a column you don’t have. If you don’t do something now, you’ll never be able to get back to the original order, which could have meaning for both the agency and for fact-checking."
  },
  {
    "objectID": "xl-refresher.html#video-walkthrough",
    "href": "xl-refresher.html#video-walkthrough",
    "title": "6  Spreadsheet Refresher",
    "section": "6.3 Video walkthrough",
    "text": "6.3 Video walkthrough\nThese first steps, along with adding an ID row, are shown here. You can follow along with the same dataset.\n\n\n\n\nGetting started with Google Sheets"
  },
  {
    "objectID": "xl-refresher.html#keyboard-shortcuts",
    "href": "xl-refresher.html#keyboard-shortcuts",
    "title": "6  Spreadsheet Refresher",
    "section": "6.4 Keyboard shortcuts",
    "text": "6.4 Keyboard shortcuts\nGoogle Sheets keyboard shortcuts can be found in the menu: Help, then Keyboard Shortcuts.\n\n\n\nKeyboard shortcuts"
  },
  {
    "objectID": "xl-formulas.html#formulas-in-spreadsheets",
    "href": "xl-formulas.html#formulas-in-spreadsheets",
    "title": "8  Spreadsheet Formulas",
    "section": "8.1 Formulas in spreadsheets",
    "text": "8.1 Formulas in spreadsheets\nEvery formula begins with the equals sign (=). Rather than the values you want to work with in the formula, you’ll use references to other cells in the sheet.\nThe easiest formulas are simple arithmetic: adding, subtracting, multiplying and dividing two or more cells. You’ll just use simple operators to do this:\n\n\n\noperator\nsymbol\nexample\n\n\n\n\naddition\n+\n=A2+B2\n\n\nsubtraction\n-\n=A2-B2\n\n\nmultiplication\n*\n=A2*B2\n\n\ndivision\n/\n=A2/B2\n\n\n\nHere’s what a spreadsheet looks like while editing some simple arithmetic:\n\n\n\nformula\n\n\nThe other kind of formula is a function. A function is a command that has a name, and requires arguments – usually the cell addresses or the range of addresses that it will act on. Every programming language has functions built in and many have extensions, or packages or libraries, that add even more as users find things they want to do more efficiently. You begin using a function the same way you begin a formula – with an = sign. Here are three common functions that create summary statistics for the numbers contained in a range of addresses. A range is a set of cells defined by its corner cell address: the top left through the bottom right.\nYou’ll usually use them on a single column at a time.\n\n\n\n\n\n\n\nFormula\nWhat it does\n\n\n\n\n=SUM(start:finish)\nAdds up the numbers between start and finish\n\n\n=AVERAGE(start:finish)\nComputes the mean of the numbers\n\n\n=MEDIAN(start:finish)\nDerives the median of the numbers\n\n\n\n…where “start” means the first cell you want to include, and finish means the last cell. Use the cell address of the first number you want to include , a colon, then the cell address of the last number you want to include. You can also select them while you’re editing the formula.\nHere’s an example of adding up all of the rows in a list by county:\n\n\n\nformula"
  },
  {
    "objectID": "xl-formulas.html#common-spreadsheet-arithmetic",
    "href": "xl-formulas.html#common-spreadsheet-arithmetic",
    "title": "8  Spreadsheet Formulas",
    "section": "8.2 Common spreadsheet arithmetic",
    "text": "8.2 Common spreadsheet arithmetic\nThe budget document shows three years’ of data: The actual spending in the fiscal year that ended in 2016; the spending that was estimated for the end of fiscal year 2017; and the proposed spending for fiscal year 2018. The first page of the document shows these amounts for broad spending categories.\nYou may want to widen the columns and format the numbers before you start:\n\n\n\n\n\n\n8.2.1 Check the government’s math with SUM\nOur first job is to make sure the government has provided us data that adds up. To do that, we’ll SUM all of the departments’ spending.\nTo add up the numbers from FY 2020 Actual, enter the following formula in cell C16, just below the number provided by the government:\n  =SUM(C2:C13)\n  and hit the enter key\nCopy that formula to the right. Notice how the formula changes the addresses that it is using as you move to the right – it’s adjusted them to refer to the current column.\n\n\n\n\n\n\n\n8.2.2 Change in spending\nThe increase or decrease in projected spending from 2017 to 2018 is just the difference between the two values, beginning in cell F3\n  new-old, or  =E2-D2\nWhen you copy it down, note how the references to each row also adjusted. In line 3, it’s E3-D3, and so on. Excel and other spreadsheets assume that, most of the time, you want these kinds of adjustments to be made.\n\n\n\n\n\n\n\n8.2.3 Percent change\nWe can’t tell the rate of growth for each department until we calculate the percent change from one year to another. Now that we already have the change, the percent change is easy. The formula is:\n  ( new - old ) / old\n\n  .. or just scream \"NOO\"\nThe new-old is already in column F, so all that’s left is to divide again. In grade school, you also had to move the decimal place over two spots, since the concept of percent change is “out of 100”. Excel formats will do that for you.\nRemember, it’s always (new-old)/old , NOT the big one minus the little one. Doing it correctly, the answer could be negative, meaning the value fell.\n\n\n\nformula\n\n\nWhen you’re done, you can format the answer as a percentage to get it into whole numbers.\nIt’s also worth comparing the picture you get by looking at raw numbers vs. percentages. It’s instructive that federal grants are up 308%.\n\n\n8.2.4 Parts of a whole: percent of total\nWe’d also like to know what portion of the total spending is eaten up by each department. To do that, we need the percent of total.\nIn our case, let’s use the total that the government gave us. In practice, you’d have to decide what to do if your figures didn’t match those provided by officials. You can’t assume that the total is wrong – you could be missing a category, or there could be a mistake in one of the line items.\nThe formula for percent of total is:\n  category / total\nHere’s a good trick with spreadsheets when you need to divide against a fixed total. You don’t have to type in each formula one by one, though. Instead, you’ll use anchors, known in spreadsheets as “absolute references”. Think of a dollar sign as an anchor or stickpin, holding down the location of part of your formula. If you put the stickpin before the letter in the formula, it holds the column in place. If you put it before the number, it holds the row in place. If you put it in both places, it holds the cell in place.\nIn this case, we want to see what percentage property taxes, income taxes, etc. are of the total revenues in FY22, which is $4,331,049,486 (cell E14). Let’s figure it out.\n\nLeft click column F, insert column to the left. Name it Pct of Total\nCreate formula to divide property taxes into total revenues: =(E2/E14)\nModify forumula so it will anchor to the E14 as you move down the spreadsheet =(E2/$E$14)\nCopy formula down to F13"
  },
  {
    "objectID": "xl-formulas.html#while-were-at-it-two-kinds-of-averages",
    "href": "xl-formulas.html#while-were-at-it-two-kinds-of-averages",
    "title": "8  Spreadsheet Formulas",
    "section": "8.3 While we’re at it: two kinds of averages",
    "text": "8.3 While we’re at it: two kinds of averages\nAlthough it doesn’t make a lot of sense in this context, we’ll go ahead and calculate the average or mean size of each department, and then calculate the median size.\nSimple average, or mean\nA simple average, also known as the mean, is skewed toward very high or very low values. Its formula is\n    sum of pieces / # of pieces that were summed\nBut in Google Sheets, all we need is the word AVERAGE:\n    =AVERAGE(C2:C9)\nMedian\nIn Google Sheets, you can get the median of a list of numbers by just using the formula, MEDIAN()\n  = MEDIAN(C2:C9)\nDoing simple calclutions like this on data that is provided to you by the government lets you ask better questions when you get an interview, and may even convince officials to talk with you. There’s a big difference between asking them to tell you what the budget numbers are, and asking them to explain specific results!"
  },
  {
    "objectID": "xl-formulas.html#faqs",
    "href": "xl-formulas.html#faqs",
    "title": "8  Spreadsheet Formulas",
    "section": "8.4 FAQs",
    "text": "8.4 FAQs\n\nShould I use average or median?\nIt depends. Averages are easier to explain but can be misleading. Usually, if they’re very different, median will be a better representation of the typical person, city or department. Averages in these cases are more like totals.\n\n\nMy percents are small numbers with decimal points\nUse the format as a % button to move the decimal point over two places and insert the percentage symbol."
  },
  {
    "objectID": "r-load-analyze-visualize.html",
    "href": "r-load-analyze-visualize.html",
    "title": "12  Loading and Analyzing Data",
    "section": "",
    "text": "This tutorial, based on my 2024 presentation for the National Institute for Computer Assisted Reporting (NICAR), will show you the essential workflow for any data analysis project in R. You will learn to import data, explore it, use basic commands to sort and filter and build summary tables. You will build a basic data visualization from your work – all in R code.\nYou will be executing commands in this document that are contained in “chunks,” which are separate from the text and contain live R code. Click the green arrow at the right on line 6 and run the help.start() command\n\nhelp.start()\n\nstarting httpd help server ... done\n\n\nIf the browser launched by '/usr/bin/open' is already running, it is\n    *not* restarted, and you must switch to its window.\nOtherwise, be patient ...\n\n\n  In the bottom right window of R Studio, you will see a Help window that displays basic help commands for the program. \n\n12.0.1 Install software to grab data\nTidyverse: Eight separate software packages to perform\ndata import, tidying, manipulation, visualisation, and            programming\n\nRio: Easy importing features \nJanitor: Data cleaning\nYou should have installed tidyverse already. If not, then delete the hashtag in front of install.packages(“tidyverse”) and run the code chunk at line 22.\n\noptions(repos = \"https://cloud.r-project.org\") \ninstall.packages(\"tidyverse\")\n\nalso installing the dependencies 'broom', 'conflicted', 'dbplyr', 'forcats', 'lubridate', 'readxl'\n\n\n\nThe downloaded binary packages are in\n    /var/folders/4j/5v_ymx217295nl9fk7hw_zp80000gn/T//RtmpuYgfLE/downloaded_packages\n\ninstall.packages(\"rio\")\n\nalso installing the dependencies 'R.oo', 'R.methodsS3', 'writexl', 'R.utils'\n\n\n\nThe downloaded binary packages are in\n    /var/folders/4j/5v_ymx217295nl9fk7hw_zp80000gn/T//RtmpuYgfLE/downloaded_packages\n\ninstall.packages(\"janitor\")\n\n\nThe downloaded binary packages are in\n    /var/folders/4j/5v_ymx217295nl9fk7hw_zp80000gn/T//RtmpuYgfLE/downloaded_packages\n\n\nRemember, package installation usually is a one-time thing on your hard drive. But when you need to load the software libraries each time you start a script. Libraries are bits of software you will have to load each time into R to make things run.\n\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(janitor)\n\nCheck to see what’s installed by clicking on “Packages” tab in File Manager, lower right pane \n\n\n12.0.2 Data\nWe will work with a dataset of MediaSalaries that I cleaned and modified slightly for this tutorial. Some of the detail has been removed so we can make calculations. This MediaSalaries sheet was a crowdsourced project involving reporters worldwide to share information about salaries and benefits. Open this file in Google Sheets\n1) Select Salaries tab\n\nIRE Old School: Four Corners Test!\n13 Columns\n1658 Rows\n\nNumberic data in Salary, Years Experience\nMixed string data in Gender Identity / Ethnicity, Job duties\n \n\n\n12.0.3 Import Data\nWe'll now load this data into R. You can load spreadsheets from the Internet as follows:\n\nMediaBucks &lt;- rio::import(\"https://docs.google.com/spreadsheets/d/1jkbQFwIdaWv8K00Ad6Wq7ZxFTUPFQA-g/edit#gid=1655992481\", which = \"RealMediaSalaries2\")\n\n What happened? Look at the table\n\nView(MediaBucks)\n\nWhat happened?\nR grabbed the spreadsheet from the folder\nWe told R to grab the first sheet, RealMediaSalaries2\nR created a dataframe called MediaBucks\nbasics of R: &lt;- is known as an “assignment operator.”\nIt means: “Make the object named to the left equal to the output of the code to the right.”\n \n\n\n12.0.4 Explore Data\nClick the green arrow code chunk to get the answers below.\nHow many rows?\n\nnrow(MediaBucks)\n\n[1] 1658\n\n\nHow many columns?\n\nncol(MediaBucks)\n\n[1] 13\n\n\nDimensions: Gives number rows, then columns\n\ndim(MediaBucks)\n\n[1] 1658   13\n\n\nNames of your columns\n\ncolnames(MediaBucks)\n\n [1] \"TITLE\"                     \"COMPANY\"                  \n [3] \"Salary\"                    \"Salary_Details\"           \n [5] \"Salary_Details2\"           \"Race\"                     \n [7] \"Gender\"                    \"YEARS_EXPERIENCE\"         \n [9] \"LOCATION\"                  \"JOB_DUTIES\"               \n[11] \"PREV_SALARIES_TITLES\"      \"SALARY_original\"          \n[13] \"Gender_Ethnicity_Original\"\n\n\nOR\n\nnames(MediaBucks)\n\n [1] \"TITLE\"                     \"COMPANY\"                  \n [3] \"Salary\"                    \"Salary_Details\"           \n [5] \"Salary_Details2\"           \"Race\"                     \n [7] \"Gender\"                    \"YEARS_EXPERIENCE\"         \n [9] \"LOCATION\"                  \"JOB_DUTIES\"               \n[11] \"PREV_SALARIES_TITLES\"      \"SALARY_original\"          \n[13] \"Gender_Ethnicity_Original\"\n\n\nCheck data types\n\nstr(MediaBucks)\n\n'data.frame':   1658 obs. of  13 variables:\n $ TITLE                    : chr  \"Photojournalist\" \"Staff Writer\" \"Staff reporter\" \"Reporter\" ...\n $ COMPANY                  : chr  \"College Student Newspaper\" \"Paxton Media\" \"Schurz Communications Inc.\" \"Hearst Newspapers\" ...\n $ Salary                   : num  0 12 12 13.2 14.9 ...\n $ Salary_Details           : chr  \"\" \"hour\" \"hour\" \"hour\" ...\n $ Salary_Details2          : chr  \"\" \"anhour\" \"-2012\" \"~32,000/year\" ...\n $ Race                     : chr  \"asian\" \"white\" \"white\" \"white\" ...\n $ Gender                   : chr  \"male\" \"female\" \"female\" \"female\" ...\n $ YEARS_EXPERIENCE         : chr  \"3\" \"8\" \"2\" \"3\" ...\n $ LOCATION                 : chr  \"\" \"Georgia\" \"Central Kentucky\" \"Houston\" ...\n $ JOB_DUTIES               : chr  \"Photo\" \"Write and cover news stories, photograph news, write monthly health magazine, social media director\" \"Reported on anything and everything: local government, breaking news, features, op/eds, columns. Took pictures,\"| __truncated__ \"Report on communities outside of the Houston metro area, take photos, produce online and print content, pitch s\"| __truncated__ ...\n $ PREV_SALARIES_TITLES     : chr  \"\" \"\" \"\" \"\" ...\n $ SALARY_original          : chr  \"0\" \"$12 an hour\" \"$12/hour (2012)\" \"13.25/hour ~ 32,000/year \" ...\n $ Gender_Ethnicity_Original: chr  \"Cis male asian\" \"White female\" \"cis white female\" \"Cis white female\" ...\n\n\nLet’s look at the first six rows\n\nhead(MediaBucks)\n\n            TITLE                    COMPANY Salary Salary_Details\n1 Photojournalist  College Student Newspaper   0.00               \n2    Staff Writer               Paxton Media  12.00           hour\n3  Staff reporter Schurz Communications Inc.  12.00           hour\n4        Reporter          Hearst Newspapers  13.25           hour\n5  Staff Reporter           Ogden Newspapers  14.91           hour\n6   Desk Assitant                       KTLA  15.00           hour\n  Salary_Details2     Race Gender    YEARS_EXPERIENCE         LOCATION\n1                    asian   male                   3                 \n2          anhour    white female                   8          Georgia\n3           -2012    white female                   2 Central Kentucky\n4    ~32,000/year    white female                   3          Houston\n5         perhour    white   male 3+ years experience             Utah\n6                 noanswer female                   2      Los Angeles\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    JOB_DUTIES\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Photo\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                          Write and cover news stories, photograph news, write monthly health magazine, social media director\n3                                                                                                                                                                                                                                                                                                                                                                       Reported on anything and everything: local government, breaking news, features, op/eds, columns. Took pictures, managed web uploads and social media accounts, produced short videos. \n4                                                                                                                                                                                                                                                                                                                                                                                                                             Report on communities outside of the Houston metro area, take photos, produce online and print content, pitch story ideas, etc. \n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   daily beat reporting, photos, social media\n6 Organize daily field drives and retrieves file videos\\nUse FTP system to send/receive video files from the field\\nMakes beat checks of police and fire departments\\nLog/transcribe daily video feeds\\nAnswers viewer phone calls, taking stories from viewers\\nChecks for possible stories via all social media channels\\nChecks email for possible stories and upcoming news events\\nListens to viewers complaints; accepts criticism in an even handed manner; and offers suggestions or answers as appropriate\\nWatch and log daily competition newscasts\n  PREV_SALARIES_TITLES           SALARY_original Gender_Ethnicity_Original\n1                                              0            Cis male asian\n2                                    $12 an hour              White female\n3                                $12/hour (2012)          cis white female\n4                      13.25/hour ~ 32,000/year           Cis white female\n5                                $14.91 per hour            cis white male\n6                                       $15/hour                cis female\n\n\nHere is a quick way to view the range of your data\n\nsummary(MediaBucks$Salary)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      0   42000   60000   64194   78000  770000       4 \n\n\nSize and scope\n\nsum(MediaBucks$Salary, na.rm=TRUE)\n\n[1] 106177432\n\n\n$106 million! for 1,658 journalists\nContext: NYT earnings in 2020 = $100 m Facebook profit for one day: $114 million (Q42021=$10.3B)\naverage\n\nmean(MediaBucks$Salary, na.rm=TRUE)\n\n[1] 64194.34\n\n\nDistribution\n\nquantile(MediaBucks$Salary, c(0.1, 0.2, 0.3, 0.4,0.5, 0.6, 0.7, 0.8, 0.9), na.rm=TRUE)\n\n   10%    20%    30%    40%    50%    60%    70%    80%    90% \n 28720  39000  45000  52000  60000  65000  75000  84000 101700 \n\n\n\nquantile(MediaBucks$Salary, c(0.25, 0.50, 0.75, 0.9, 0.99), na.rm=TRUE)\n\n   25%    50%    75%    90%    99% \n 42000  60000  78000 101700 200000 \n\n\n\n\n\n12.0.5 Navigation Tips\nShortcut Commands\nTab - Autocomplete\nIn Console Window (lower left) \n--Control (or Command) + UP arrow - last lines run\nControl (or Command) + Enter - Runs current or selected lines of code in the top left box of RStudio\nShift + Control (or Command) +P - Reruns previous region code\n \n\n\n12.0.6 Dplyr\ndplyr has many tools for data analysis   \nselect Choose which columns to include  \nfilter Filter the data \narrange Sort the data, by size for continuous variables, by date, or alphabetically \ngroup_by Group the data by a categorical variable \n\nBuild a simple summary table by Gender\n\nMediaBucks %&gt;% \n  select(Gender, Salary) %&gt;% \n  group_by(Gender) %&gt;% \n  summarize(Total = sum(Salary, na.rm=TRUE))\n\n# A tibble: 4 × 2\n  Gender       Total\n  &lt;chr&gt;        &lt;dbl&gt;\n1 female   63198034.\n2 male     35201242.\n3 na        3061718.\n4 noanswer  4716438.\n\n\nWhat is the sample size?\n\nMediaBucks %&gt;% \n  count(Gender) %&gt;% \n  arrange(desc(n))\n\n    Gender    n\n1   female 1025\n2     male  503\n3 noanswer   71\n4       na   59\n\n\nBetter idea: Check Averages!\nBuild a simple summary table by Gender\n\nMediaBucks %&gt;% \n  select(Gender, Salary) %&gt;% \n  group_by(Gender) %&gt;% \n  summarize(Avg_Salary = mean(Salary, na.rm=TRUE))\n\n# A tibble: 4 × 2\n  Gender   Avg_Salary\n  &lt;chr&gt;         &lt;dbl&gt;\n1 female       61717.\n2 male         69983.\n3 na           52788.\n4 noanswer     68354.\n\n\nQuick filter out hourly workers\n\nMediaSalary &lt;- MediaBucks %&gt;% \n  filter(Salary &gt;= 1000)\n\nJust give me a list of the top 10 salaries and companies: use slice_max. slice_max and slice_min are features in the Dplyr library (part of Tidyverse) that produce quick summary tables. See what else you can do with the slice commands.\n\nMediaBucks %&gt;% \n  select(COMPANY, Salary) %&gt;% \n  slice_max(Salary, n = 10)\n\n                 COMPANY Salary\n1     Tribune Publishing 770000\n2              The Onion 550008\n3  G/O Media (The Onion) 500000\n4  G/O Media (The Onion) 500000\n5               VoxMedia 400000\n6             ProPublica 395000\n7    Digital_First_Media 375000\n8          The Intercept 368249\n9           NewYorkTimes 350000\n10             LBI Media 291200\n\n\nQuestions:\n1: View the range of your data    \n2: Number of rows  \n3: Number of rows cut with filter  \n\n\n\n12.0.7 Find Your News Organization\nFilter\n\nWSJ &lt;- subset(MediaBucks, COMPANY==\"WallStreetJournal\")  \n\n\nsummary(WSJ$Salary)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n     38   41000   51100   64275   75750  236000 \n\n\nUsing Wildcards\n\nJournal &lt;- subset(MediaBucks, grepl(\"?Journal\", COMPANY))\n\n\nBloom &lt;- subset(MediaBucks, grepl(\"?Bloomberg\", COMPANY))\n\n ### More Tables\nBuild a table with several companies of your choice\n\nBigBoys &lt;- filter(MediaSalary, COMPANY %in% c(\"NewYorkTimes\", \"WallStreetJournal\", \"Bloomberg\"))    \n\nTable with just reporter salaries\n\nReporters &lt;- subset(MediaBucks, grepl(\"?reporter\", TITLE))\nsummary(Reporters$Salary)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n     12   35000   50625   57077   67250  230504 \n\n\nQuestions:\n1: Who is making $230,504 as a reporter???   \n2: Make a table for editors, figure out medians.   \n3: Find highest paid editor. Resent them.   \n4: Make a table for any position involving data  \nTable with Black reporters at Wall Street Journal\n\nWSJ_Black &lt;- MediaBucks %&gt;% filter(Race ==\"black\", COMPANY == \"WallStreetJournal\")\n\nBuild a simple summary table by Race\n\nRace &lt;- MediaBucks %&gt;% \n  select(Race, Salary) %&gt;% \n  group_by(Race) %&gt;% \n  summarize(Avg_Salary = mean(Salary, na.rm=TRUE)) %&gt;% \n  arrange(desc(Avg_Salary))\nRace\n\n# A tibble: 13 × 2\n   Race       Avg_Salary\n   &lt;chr&gt;           &lt;dbl&gt;\n 1 chinese        76167.\n 2 australian     75000 \n 3 african        73485.\n 4 hispanic       70481.\n 5 black          69371.\n 6 poc            68061.\n 7 asian          66427.\n 8 noanswer       64925.\n 9 latina         64806.\n10 white          63025.\n11 mixed          55756.\n12 mideastern     51833.\n13 native         50000 \n\n\nWait! What are the totals by race?\n\nMediaBucks %&gt;% \n  count(Race) %&gt;% \n  arrange(desc(n))\n\n         Race    n\n1       white 1094\n2    noanswer  192\n3         poc  115\n4       asian   77\n5       black   57\n6    hispanic   53\n7      latina   23\n8       mixed   22\n9     african   13\n10 mideastern    7\n11    chinese    3\n12 australian    1\n13     native    1\n\n\nAdvanced: Build a summary table and count by race\n\nMediaBucks %&gt;% \n  select(Race, Salary) %&gt;% \n group_by(Race) %&gt;% \n  summarize(Total=n(),\n            Avg = mean(Salary, na.rm=TRUE)) %&gt;% \n  arrange(desc(Total))\n\n# A tibble: 13 × 3\n   Race       Total    Avg\n   &lt;chr&gt;      &lt;int&gt;  &lt;dbl&gt;\n 1 white       1094 63025.\n 2 noanswer     192 64925.\n 3 poc          115 68061.\n 4 asian         77 66427.\n 5 black         57 69371.\n 6 hispanic      53 70481.\n 7 latina        23 64806.\n 8 mixed         22 55756.\n 9 african       13 73485.\n10 mideastern     7 51833.\n11 chinese        3 76167.\n12 australian     1 75000 \n13 native         1 50000 \n\n#details: https://stackoverflow.com/questions/36183601/average-and-count-with-aggregation-in-r-with-dplyr\n\n\n\n12.0.8 Visualize\nLet’s make a simple chart of our salaries by race.\n\nRace %&gt;% \nggplot(aes(x = Race, y = Avg_Salary, fill = Avg_Salary)) +\n  geom_col(position = \"dodge\") + \n  theme(legend.position = \"none\") +\n  labs(title = \"Sample chart of race and salary using MediaSalaries\", \n       caption = \"1658 records, sample data. Graphic by Rob Wells, 8/11/2022\",\n       y=\"Average Salary\",\n       x=\"Race / Ethnicity\")\n\n\n\n\nThis is a basic chart using ggplot. To break down the code: - These lines: Race %&gt;% ggplot(aes(x = Race, y = Avg_Salary, fill = Avg_Salary)) + – Uses the Race table, calls the ggplot program, assigns the x axis to Race, y axis to Avg_Salary and fills the color according to Avg_Salary - These lines: geom_col(position = “dodge”) + theme(legend.position = “none”) + – creates a chart of columns, and removes a legend box. - These lines: labs(title = Assign the headline and captions.\n\n\n12.0.9 What You Have Learned So Far\nHow to navigate in R studio   \nHow to install libraries and packages    \nHow to import a .xlsx file into R   \nHow to obtain summary statistics (summary)   \nHow to build basic tables from a dataset   \nHow to conduct filter queries from a dataset   \n\n\n12.0.10 Questions\n1: Build a table for NewYorkTimes employees, and determine median salary of NewYorkTimes employees   \n\n#your answer here\n\n  2: Identify title, gender and race of the highest paid position at NYT  \n\n#your answer here\n\n3: Search for Bloomberg,  check median salary, compare to NYT results above.\n\n#your answer here\n\n\n\n12.0.11 Tutorials\nMaryJo Webster tutorials https://sites.google.com/view/mj-basic-data-academy/intro-to-r?authuser=0\nMerrill College eBook: Data Journalism with R and the Tidyverse https://wellsdata.github.io/data_journalism_class/_book/\nExcellent book by Sharon Machlis https://www.routledge.com/Practical-R-for-Mass-Communication-and-Journalism/Machlis/p/book/9781138726918\nFirst five chapters are free on her website. My recommendation: buy the book. https://www.machlis.com/R4Journalists/\nAll Cheat Sheets https://www.rstudio.com/resources/cheatsheets/\nAndrew Ba Tran first Data Analysis Steps Using R https://docs.google.com/presentation/d/1O0eFLypJLP-PAC63Ghq2QURAnhFo6Dxc7nGt4y_l90s/edit#slide=id.p\nBase R Cheat Sheet https://www.povertyactionlab.org/sites/default/files/r-cheat-sheet.pdf"
  }
]